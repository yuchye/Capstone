{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project: Classifying clinically actionable genetic mutations\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook 3: Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the code to identify a baseline classifier and use it to make predictions for the testing dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents\n",
    "\n",
    "- [Importing of Libraries](#Importing-of-Libraries)\n",
    "- [Data Import](#Data-Import)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing of Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tabulate import tabulate\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "TRAIN_SET_PATH = \"../assets/train_prep.csv\"\n",
    "\n",
    "GLOVE_6B_50D_PATH = \"../assets/glove.6B.50d.txt\"\n",
    "GLOVE_6B_300D_PATH = \"../assets/glove.6B.300d.txt\"\n",
    "encoding=\"utf-8\"\n",
    "\n",
    "from sklearn import linear_model, metrics, svm\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,\\\n",
    "    cross_val_score, RandomizedSearchCV, StratifiedShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc, roc_auc_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import cycle\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "import time\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import regex as re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import torch\n",
    "import transformers as ppb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "\n",
    "# Initialise random seeed for more consistent results\n",
    "from numpy.random import seed\n",
    "seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import 'train_prep' and 'test_prep' datasets\n",
    "# We use the 'keep_default_na' option to False to ensure that pandas does not re-introduce missing values\n",
    "train = pd.read_csv(\"../assets/train_prep.csv\", keep_default_na=False)\n",
    "test = pd.read_csv(\"../assets/test_prep.csv\", keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3321, 4325), (986, 4324))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "      <th>gene_ABCB11</th>\n",
       "      <th>gene_ABCC6</th>\n",
       "      <th>gene_ABL1</th>\n",
       "      <th>gene_ACVR1</th>\n",
       "      <th>gene_ADAMTS13</th>\n",
       "      <th>gene_ADGRG1</th>\n",
       "      <th>gene_AGO2</th>\n",
       "      <th>...</th>\n",
       "      <th>variation_YAP1-TFE3 Fusion</th>\n",
       "      <th>variation_YWHAE-ROS1 Fusion</th>\n",
       "      <th>variation_ZC3H7B-BCOR Fusion</th>\n",
       "      <th>variation_ZNF198-FGFR1 Fusion</th>\n",
       "      <th>variation_null1313Y</th>\n",
       "      <th>variation_null189Y</th>\n",
       "      <th>variation_null262Q</th>\n",
       "      <th>variation_null267R</th>\n",
       "      <th>variation_null399R</th>\n",
       "      <th>variation_p61BRAF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>cyclin dependent kinase cdks regulate variety ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>abstract background non small lung nsclc heter...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 4325 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  class                                               text  gene_ABCB11  \\\n",
       "0   0      1  cyclin dependent kinase cdks regulate variety ...            0   \n",
       "1   1      2  abstract background non small lung nsclc heter...            0   \n",
       "\n",
       "   gene_ABCC6  gene_ABL1  gene_ACVR1  gene_ADAMTS13  gene_ADGRG1  gene_AGO2  \\\n",
       "0           0          0           0              0            0          0   \n",
       "1           0          0           0              0            0          0   \n",
       "\n",
       "   ...  variation_YAP1-TFE3 Fusion  variation_YWHAE-ROS1 Fusion  \\\n",
       "0  ...                           0                            0   \n",
       "1  ...                           0                            0   \n",
       "\n",
       "   variation_ZC3H7B-BCOR Fusion  variation_ZNF198-FGFR1 Fusion  \\\n",
       "0                             0                              0   \n",
       "1                             0                              0   \n",
       "\n",
       "   variation_null1313Y  variation_null189Y  variation_null262Q  \\\n",
       "0                    0                   0                   0   \n",
       "1                    0                   0                   0   \n",
       "\n",
       "   variation_null267R  variation_null399R  variation_p61BRAF  \n",
       "0                   0                   0                  0  \n",
       "1                   0                   0                  0  \n",
       "\n",
       "[2 rows x 4325 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>gene_ABCB11</th>\n",
       "      <th>gene_ABCC6</th>\n",
       "      <th>gene_ABL1</th>\n",
       "      <th>gene_ACVR1</th>\n",
       "      <th>gene_ADAMTS13</th>\n",
       "      <th>gene_ADGRG1</th>\n",
       "      <th>gene_AGO2</th>\n",
       "      <th>gene_AGXT</th>\n",
       "      <th>...</th>\n",
       "      <th>variation_YAP1-TFE3 Fusion</th>\n",
       "      <th>variation_YWHAE-ROS1 Fusion</th>\n",
       "      <th>variation_ZC3H7B-BCOR Fusion</th>\n",
       "      <th>variation_ZNF198-FGFR1 Fusion</th>\n",
       "      <th>variation_null1313Y</th>\n",
       "      <th>variation_null189Y</th>\n",
       "      <th>variation_null262Q</th>\n",
       "      <th>variation_null267R</th>\n",
       "      <th>variation_null399R</th>\n",
       "      <th>variation_p61BRAF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>incidence breast increase china recent decade ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>unselected series colorectal carcinoma stratif...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 4324 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  gene_ABCB11  \\\n",
       "0   1  incidence breast increase china recent decade ...            0   \n",
       "1   2  unselected series colorectal carcinoma stratif...            0   \n",
       "\n",
       "   gene_ABCC6  gene_ABL1  gene_ACVR1  gene_ADAMTS13  gene_ADGRG1  gene_AGO2  \\\n",
       "0           0          0           0              0            0          0   \n",
       "1           0          0           0              0            0          0   \n",
       "\n",
       "   gene_AGXT  ...  variation_YAP1-TFE3 Fusion  variation_YWHAE-ROS1 Fusion  \\\n",
       "0          0  ...                           0                            0   \n",
       "1          0  ...                           0                            0   \n",
       "\n",
       "   variation_ZC3H7B-BCOR Fusion  variation_ZNF198-FGFR1 Fusion  \\\n",
       "0                             0                              0   \n",
       "1                             0                              0   \n",
       "\n",
       "   variation_null1313Y  variation_null189Y  variation_null262Q  \\\n",
       "0                    0                   0                   0   \n",
       "1                    0                   0                   0   \n",
       "\n",
       "   variation_null267R  variation_null399R  variation_p61BRAF  \n",
       "0                   0                   0                  0  \n",
       "1                   0                   0                  0  \n",
       "\n",
       "[2 rows x 4324 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting of data into Predictor (X) and Target (y) Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[[i for i in train.columns if i not in ['id', 'class']]]\n",
    "y = train['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3321, 4323), (3321,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(986, 4323)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of (Inner) Training and Validation Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our single training data set (X and y) we will create two separate datasets:\n",
    "- (Inner) Training Dataset: this will be used to train our models (this will take 75% of the original training dataset)\n",
    "- Validation Dataset: this will be used to validate our trained models (e.g. check for overfitting) (this will take 25% of our total 'posts' dataset\n",
    "\n",
    "To create our datasets, we use train_test_split with the stratify option to ensure a consistent mix of values for the target feature within the created datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2490, 4323), (2490,), (831, 4323), (831,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the indices to prevent spurious rows from appearing later during merging\n",
    "X_train.reset_index(inplace=True, drop=True)\n",
    "X_val.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation of word embeddings using TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our baseline model, we use the TfidfVectorizer from sklearn, which creates weighted word embeddings (also knon as vectors), where each word embedding consists of the number of times each word is observed in each descriptive text string, weighted by their inverse document frequency (i.e. heavier weights are assigned to words that are less frequent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a CountVectorizer object\n",
    "tvec = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 19.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_tvec = tvec.fit_transform(X_train['text'])\n",
    "X_val_tvec = tvec.transform(X_val['text'])\n",
    "X_test_tvec = tvec.transform(X_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2490, 72190), (831, 72190), (986, 72190))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tvec.shape, X_val_tvec.shape, X_test_tvec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tvec_df = pd.DataFrame(X_train_tvec.toarray(), columns=tvec.get_feature_names())\n",
    "X_val_tvec_df = pd.DataFrame(X_val_tvec.toarray(), columns=tvec.get_feature_names())\n",
    "X_test_tvec_df = pd.DataFrame(X_test_tvec.toarray(), columns=tvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2490, 72190), (831, 72190), (986, 72190))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tvec_df.shape, X_val_tvec_df.shape, X_test_tvec_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaaa</th>\n",
       "      <th>aaaaa</th>\n",
       "      <th>aaaaaagaaaattttagataaaaagag</th>\n",
       "      <th>aaaaaatcccaaccataacaaaattt</th>\n",
       "      <th>aaaaaatcctcttgtgttcag</th>\n",
       "      <th>aaaaaccggtatgaaaagcagcataccgaacaataaggagatccc</th>\n",
       "      <th>aaaaag</th>\n",
       "      <th>aaaaataactactgc</th>\n",
       "      <th>...</th>\n",
       "      <th>zytolight</th>\n",
       "      <th>zytomed</th>\n",
       "      <th>zytovision</th>\n",
       "      <th>zyx</th>\n",
       "      <th>zyxin</th>\n",
       "      <th>zz</th>\n",
       "      <th>zzo</th>\n",
       "      <th>zzq</th>\n",
       "      <th>zzsi</th>\n",
       "      <th>zzzq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 72190 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    aa  aaa  aaaa  aaaaa  aaaaaagaaaattttagataaaaagag  \\\n",
       "0  0.0  0.0   0.0    0.0                          0.0   \n",
       "1  0.0  0.0   0.0    0.0                          0.0   \n",
       "2  0.0  0.0   0.0    0.0                          0.0   \n",
       "3  0.0  0.0   0.0    0.0                          0.0   \n",
       "4  0.0  0.0   0.0    0.0                          0.0   \n",
       "\n",
       "   aaaaaatcccaaccataacaaaattt  aaaaaatcctcttgtgttcag  \\\n",
       "0                         0.0                    0.0   \n",
       "1                         0.0                    0.0   \n",
       "2                         0.0                    0.0   \n",
       "3                         0.0                    0.0   \n",
       "4                         0.0                    0.0   \n",
       "\n",
       "   aaaaaccggtatgaaaagcagcataccgaacaataaggagatccc  aaaaag  aaaaataactactgc  \\\n",
       "0                                            0.0     0.0              0.0   \n",
       "1                                            0.0     0.0              0.0   \n",
       "2                                            0.0     0.0              0.0   \n",
       "3                                            0.0     0.0              0.0   \n",
       "4                                            0.0     0.0              0.0   \n",
       "\n",
       "   ...  zytolight  zytomed  zytovision  zyx  zyxin   zz  zzo  zzq  zzsi  zzzq  \n",
       "0  ...        0.0      0.0         0.0  0.0    0.0  0.0  0.0  0.0   0.0   0.0  \n",
       "1  ...        0.0      0.0         0.0  0.0    0.0  0.0  0.0  0.0   0.0   0.0  \n",
       "2  ...        0.0      0.0         0.0  0.0    0.0  0.0  0.0  0.0   0.0   0.0  \n",
       "3  ...        0.0      0.0         0.0  0.0    0.0  0.0  0.0  0.0   0.0   0.0  \n",
       "4  ...        0.0      0.0         0.0  0.0    0.0  0.0  0.0  0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 72190 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tvec_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining word embeddings with dummy columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Concatenate the components parts of the dataframe\n",
    "X_train = pd.concat([X_train, X_train_tvec_df], axis=1)\n",
    "X_val = pd.concat([X_val, X_val_tvec_df], axis=1)\n",
    "X_test = pd.concat([X_test, X_test_tvec_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(columns=['text'], inplace=True)\n",
    "X_val.drop(columns=['text'], inplace=True)\n",
    "X_test.drop(columns=['text'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2490, 76511), (831, 76511), (986, 76511))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_ABCB11</th>\n",
       "      <th>gene_ABCC6</th>\n",
       "      <th>gene_ABL1</th>\n",
       "      <th>gene_ACVR1</th>\n",
       "      <th>gene_ADAMTS13</th>\n",
       "      <th>gene_ADGRG1</th>\n",
       "      <th>gene_AGO2</th>\n",
       "      <th>gene_AGXT</th>\n",
       "      <th>gene_AKAP9</th>\n",
       "      <th>gene_AKT1</th>\n",
       "      <th>...</th>\n",
       "      <th>zytolight</th>\n",
       "      <th>zytomed</th>\n",
       "      <th>zytovision</th>\n",
       "      <th>zyx</th>\n",
       "      <th>zyxin</th>\n",
       "      <th>zz</th>\n",
       "      <th>zzo</th>\n",
       "      <th>zzq</th>\n",
       "      <th>zzsi</th>\n",
       "      <th>zzzq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 76511 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   gene_ABCB11  gene_ABCC6  gene_ABL1  gene_ACVR1  gene_ADAMTS13  gene_ADGRG1  \\\n",
       "0            0           0          0           0              0            0   \n",
       "1            0           0          0           0              0            0   \n",
       "2            0           0          0           0              0            0   \n",
       "3            0           0          0           0              0            0   \n",
       "4            0           0          0           0              0            0   \n",
       "\n",
       "   gene_AGO2  gene_AGXT  gene_AKAP9  gene_AKT1  ...  zytolight  zytomed  \\\n",
       "0          0          0           0          0  ...        0.0      0.0   \n",
       "1          0          0           0          0  ...        0.0      0.0   \n",
       "2          0          0           0          0  ...        0.0      0.0   \n",
       "3          0          0           0          0  ...        0.0      0.0   \n",
       "4          0          0           0          0  ...        0.0      0.0   \n",
       "\n",
       "   zytovision  zyx  zyxin   zz  zzo  zzq  zzsi  zzzq  \n",
       "0         0.0  0.0    0.0  0.0  0.0  0.0   0.0   0.0  \n",
       "1         0.0  0.0    0.0  0.0  0.0  0.0   0.0   0.0  \n",
       "2         0.0  0.0    0.0  0.0  0.0  0.0   0.0   0.0  \n",
       "3         0.0  0.0    0.0  0.0  0.0  0.0   0.0   0.0  \n",
       "4         0.0  0.0    0.0  0.0  0.0  0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 76511 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling of imbalanced classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7    0.287149\n",
       "4    0.206426\n",
       "1    0.171084\n",
       "2    0.136145\n",
       "6    0.082731\n",
       "5    0.072691\n",
       "3    0.026908\n",
       "9    0.011245\n",
       "8    0.005622\n",
       "Name: class, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7    715\n",
       "4    514\n",
       "1    426\n",
       "2    339\n",
       "6    206\n",
       "5    181\n",
       "3     67\n",
       "9     28\n",
       "8     14\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note above that the **training set is highly imbalanced** -- i.e. classes 4 and 7 alone take up almost 50% of all classes found in the training set.\n",
    "\n",
    "To deal with this, we will need to oversample one or more of the minority classes rather than undersample the majority classes as the latter will remove valuable data for our modelling.\n",
    "\n",
    "We oversample by creating synthetic samples using imblearn’s SMOTE or Synthetic Minority Oversampling Technique. SMOTE uses a nearest neighbors algorithm to generate new and synthetic data we can use for training our model. We generate new samples **only in the training set** to ensure our model generalises well to unseen data. Instead of oversampling all minority classes, we instead oversample only the 3 most infrequent classes ('3', '9' and '8') such that we have 181 data points for each of these specific minority classes, which is the no. of datapoints having the '5' class. Our previous attempts to oversample **all** minority classes led to an over-expansion of the y_train dataset which in turn led to unmanageable execution times when performing the subsequent modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a SMOTE object to oversample minority classes\n",
    "sm = SMOTE(random_state=42, sampling_strategy={3:181, 9:181, 8:181})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 40.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train, y_train = sm.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2924, 76511), (2924,))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7    715\n",
       "4    514\n",
       "1    426\n",
       "2    339\n",
       "6    206\n",
       "9    181\n",
       "5    181\n",
       "3    181\n",
       "8    181\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, we have oversampled the three most infrequent classes such that there are 181 samples for each of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomised Search for optimal classifier parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To manage the total time and resources used to tune the classifier parameters, we use the RandomizedSearchCV to randomly select parameters from the specified ranges of parameters to give the best cross-validated accuracy score on the training dataset, with a maximum of 10 iterations. We specify the range of parameters for each classifer based on experience and past results of running the RandomizedSearchCV.\n",
    "\n",
    "We select the best classifier as the one with the highest accuracy score on the **validation dataset**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have selected the models below for modelling purposes.\n",
    "estimators = {\n",
    "    'lr': LogisticRegression(random_state=42),\n",
    "    'mnb': MultinomialNB(),\n",
    "    'knn': KNeighborsClassifier(),\n",
    "    'ada': AdaBoostClassifier(random_state=42),\n",
    "    'dtree': DecisionTreeClassifier(random_state=42),\n",
    "    'rf': RandomForestClassifier(random_state=42),\n",
    "    'etree': ExtraTreesClassifier(random_state=42),\n",
    "    'svm': SVC(random_state=42)\n",
    "}.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'lr': {\n",
    "        # 'liblinear' solver has been excluded as a potential solver as it cannot learn a true multinomial\n",
    "        # (multiclass) model; instead, the optimization problem is decomposed in a “one-vs-rest”\n",
    "        # fashion so separate binary classifiers are trained for all classes.\n",
    "        # 'lbfgs' solver has also been excluded as it fails to converge through past attempts\n",
    "        'lr__solver': ['sag','saga'], \n",
    "        'lr__penalty': ['l1', 'l2'],\n",
    "        'lr__C': np.logspace(-3, 1, 5),\n",
    "        'lr__multi_class':['multinomial'] \n",
    "    },\n",
    "    'mnb': {\n",
    "        'mnb__alpha': np.linspace(0.5, 1.5, 3),\n",
    "        'mnb__fit_prior': [True, False],  \n",
    "    },\n",
    "    'knn': {\n",
    "        'knn__n_neighbors': [3, 5, 7]\n",
    "    },\n",
    "    'ada': {\n",
    "        'ada__n_estimators': [50, 100, 150],\n",
    "        'ada__learning_rate': [1, 1.5, 2]\n",
    "    },\n",
    "    'dtree': {\n",
    "        'dtree__max_features': ['auto', 'sqrt', 'log2', None],\n",
    "        'dtree__min_samples_split': [4, 6, 8],\n",
    "        'dtree__min_samples_leaf': [2, 3, 4]\n",
    "    },\n",
    "    'rf': {\n",
    "        'rf__n_estimators': [100, 200, 300],\n",
    "        'rf__class_weight': ['balanced'], # 'balanced' will help to deal with our imbalanced classes\n",
    "        'rf__min_samples_split':[5, 10, 15],\n",
    "        'rf__min_samples_leaf':[2, 3, 4]    \n",
    "    },\n",
    "    'etree': {\n",
    "        'etree__max_features': ['auto', 'sqrt', 'log2', None],\n",
    "        'etree__min_samples_split': [4, 6, 8],\n",
    "        'etree__min_samples_leaf': [2, 3, 4]\n",
    "    },\n",
    "    'svm': {\n",
    "        'svm__C': np.logspace(-3, 3, 10),\n",
    "        'svm__kernel': ['linear','poly', 'rbf', 'sigmoid']\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use RandomizedSearchCV to select the optimal parameters for each classifier that produces the best 3-fold cross-validated mean accuracy score based on the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  30 out of  30 | elapsed: 102.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  lr\n",
      "Fitting time: 6981.50004863739\n",
      "Best parameters: {'lr__solver': 'sag', 'lr__penalty': 'l2', 'lr__multi_class': 'multinomial', 'lr__C': 10.0}\n",
      "Best accuracy cross validation score: 0.7041752224503764\n",
      "Training dataset accuracy: 0.9976060191518468\n",
      "Validation dataset accuracy: 0.6293622141997594\n",
      "\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  18 out of  18 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  mnb\n",
      "Fitting time: 86.08883881568909\n",
      "Best parameters: {'mnb__fit_prior': False, 'mnb__alpha': 0.5}\n",
      "Best accuracy cross validation score: 0.6087551554081329\n",
      "Training dataset accuracy: 0.7113543091655267\n",
      "Validation dataset accuracy: 0.5896510228640193\n",
      "\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   9 out of   9 | elapsed: 48.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  knn\n",
      "Fitting time: 3954.8259868621826\n",
      "Best parameters: {'knn__n_neighbors': 3}\n",
      "Best accuracy cross validation score: 0.5201762052686077\n",
      "Training dataset accuracy: 0.6853625170998632\n",
      "Validation dataset accuracy: 0.45126353790613716\n",
      "\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# initialise empty lists to store information later\n",
    "models = []\n",
    "parameters = []\n",
    "train_accuracy = []\n",
    "val_accuracy = []\n",
    "best_score = []\n",
    "train_roc_auc = []\n",
    "val_roc_auc = []\n",
    "sensitivity = []\n",
    "\n",
    "for k,v in estimators:\n",
    "    start = time.time()\n",
    "    pipe = Pipeline([(k,v)])\n",
    "    param = params[k]\n",
    "    randomsearch = RandomizedSearchCV(\n",
    "        n_iter=10, # we set a max. of 10 iterations\n",
    "        estimator=pipe,\n",
    "        random_state=42,\n",
    "        param_distributions=param,\n",
    "        verbose=1,\n",
    "        cv= 3,\n",
    "        # We limit the no. of jobs to ensure sufficient memory for successful execution\n",
    "        n_jobs=4,\n",
    "        return_train_score= True,\n",
    "        # RandomizedSearchCV will use best cross-validation accuracy score to determine best parameters\n",
    "        scoring = 'accuracy' \n",
    "    )\n",
    "\n",
    "    randomsearch.fit(X_train, y_train)\n",
    "    \n",
    "    model = randomsearch.best_estimator_\n",
    "    cv_score = randomsearch.cv_results_\n",
    "    best_params = randomsearch.best_params_\n",
    "\n",
    "    # predict y\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_val = model.predict(X_val)\n",
    "    \n",
    "    # print results\n",
    "    print (\"Model: \", k)\n",
    "    print (\"Fitting time: {}\".format(time.time()-start))\n",
    "    print (\"Best parameters:\", best_params)\n",
    "    print (\"Best accuracy cross validation score:\", randomsearch.best_score_)\n",
    "    print (\"Training dataset accuracy:\", accuracy_score(y_train,y_pred_train))\n",
    "    print (\"Validation dataset accuracy:\", accuracy_score(y_val,y_pred_val))\n",
    "    print (\"\")\n",
    "    \n",
    "    # append info to list\n",
    "    models.append(k)\n",
    "    best_score.append(randomsearch.best_score_)\n",
    "    parameters.append(best_params)\n",
    "    train_accuracy.append(accuracy_score(y_train,y_pred_train))\n",
    "    val_accuracy.append(accuracy_score(y_val,y_pred_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confirmation of Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Produce a summary table of the tuned classifiers\n",
    "summary = pd.DataFrame({\n",
    "    'model': models,\n",
    "    'parameters': parameters,\n",
    "    'Best accuracy cross-validation score': best_score,\n",
    "    'Training dataset accuracy': train_accuracy,\n",
    "    'Validation dataset accuracy': val_accuracy\n",
    "    })\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "summary.sort_values('Validation dataset accuracy', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "The table above summarises the optimal parameters for each candidate classifier based on the best 3-fold cross-validation accuracy score (see \"Best accuracy cross-validation score\"). The \"Training dataset accuracy\" is also shown for reference. The candidate classifiers are sorted in descending order of the last column, which measures the \"Validation dataset accuracy\" for each classifier. We focus on validation dataset accuracy to ensure that we choose the classifier that gives us the least overfitting.<br>\n",
    "<br>    \n",
    "The best classifier is the Extra Trees Classifier based on the highest validation dataset accuracy amongst the other tuned classifiers.<br>\n",
    "<br>\n",
    "    Our <b>baseline model</b> therefore consists of:\n",
    "    <br>\n",
    "    <ul>\n",
    "        <li>Word embeddings created by <b>TfidfVectorizer</b></li>\n",
    "        <li><b>Extra Trees Classifier</b> based on the optimal parameters given in the table above.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Exploration of Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We instantiate the baseline classifier based on the best parameters found above\n",
    "baseline_clf = ExtraTreesClassifier(verbose=1, n_jobs=-1, random_state=42, \\\n",
    "                                  min_samples_split=4, min_samples_leaf=3, max_features=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Fit the best classifier on the training dataset\n",
    "baseline_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation of Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now visualise one particular decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = baseline_clf.best_estimator_[100] # we choose one particular tree arbitrarily)\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "# Export as dot file\n",
    "export_graphviz(estimator, out_file='tree.dot', \n",
    "                feature_names = X_train.columns,\n",
    "                class_names = list(str(range(1,10))),\n",
    "                rounded = True, proportion = False, \n",
    "                precision = 2, filled = True)\n",
    "\n",
    "# Convert to png using Graphviz via system command\n",
    "from subprocess import call\n",
    "call(['dot', '-Tpng', 'tree.dot', '-o', 'tree.png', '-Gdpi=600'])\n",
    "\n",
    "# Display in jupyter notebook\n",
    "from IPython.display import Image\n",
    "Image(filename = 'tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curve & Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate predictions for the validation data based on our baseline model\n",
    "y_val_pred = baseline_clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarize the output\n",
    "y_train_binarized = label_binarize(y_train, classes=list(np.unique(y)))\n",
    "y_val_pred_binarized = label_binarize(y_val_pred, classes=list(np.unique(y)))\n",
    "n_classes = len(np.unique(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To come up with actual scores that can be used for ROC calculation, we use the OneVsRestClassifier coupled with a SVC (C-Support Vector) Classifier to fit the training dataset so that we can obtain the distances of each sample from the decision boundary for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "classifier = OneVsRestClassifier(svm.SVC(kernel='linear', probability=True,\n",
    "                                 random_state=42, verbose=1), n_jobs=4)\n",
    "y_score = classifier.fit(X_train, y_train_binarized).decision_function(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    # we compare our predicted labels for the validation dataset and the actual validation dataset labels\n",
    "    # first parameter of roc_curve is y_true, and second parameter is y_score\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_val_pred_binarized[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_val_pred_binarized.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot ROC curves for all the 9 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "lw=2\n",
    "colors = cycle(['rosybrown', 'firebrick', 'sienna', 'olivedrab', 'darkgreen',\\\n",
    "                'lightseagreen', 'darkturquoise', 'b', 'darkorange'])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i+1, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Multiple Classes')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note from the AUC scores ('area' metric) in the plot above that class 7 (the most predominant class in the training dataset) has a high AUC score relative to the other classes, which is not surprising. The AUC score for class 8, however, is very low. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y_prob = classifier.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate the average unweighted AUC of all pairwise combinations of classes (one-vs-one);\n",
    "# insensitive to class imbalance\n",
    "macro_roc_auc_ovo = roc_auc_score(y_val_pred_binarized, y_prob, multi_class=\"ovo\",\n",
    "                                  average=\"macro\")\n",
    "\n",
    "# Calculate the weighted average AUC of all pairwise combinations of classes (one-vs-one);\n",
    "# sensitive to class imbalance by considering the no. of true instances for each label\n",
    "weighted_roc_auc_ovo = roc_auc_score(y_val_pred_binarized, y_prob, multi_class=\"ovo\",\n",
    "                                     average=\"weighted\")\n",
    "\n",
    "# Caclulate the unweighted AUC of each class against the rest;\n",
    "# still sensitive to class imbalance because the imbalance affects the composition of each of the ‘rest’ groupings\n",
    "macro_roc_auc_ovr = roc_auc_score(y_val_pred_binarized, y_prob, multi_class=\"ovr\",\n",
    "                                  average=\"macro\")\n",
    "\n",
    "# Caclulate the weighted AUC of each class against the rest; sensitive to class imbalance\n",
    "weighted_roc_auc_ovr = roc_auc_score(y_val_pred_binarized, y_prob, multi_class=\"ovr\",\n",
    "                                     average=\"weighted\")\n",
    "\n",
    "print(\"One-vs-One ROC AUC scores for validation dataset:\\n{:.6f} (macro),\\n{:.6f} \"\n",
    "      \"(weighted by prevalence)\"\n",
    "      .format(macro_roc_auc_ovo, weighted_roc_auc_ovo))\n",
    "print(\"One-vs-Rest ROC AUC scores for validation dataset:\\n{:.6f} (macro),\\n{:.6f} \"\n",
    "      \"(weighted by prevalence)\"\n",
    "      .format(macro_roc_auc_ovr, weighted_roc_auc_ovr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "(To be written)\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Export (for Kaggle Submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "y_test_pred = baseline_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_test_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore the 'id' column since we need this for the Kaggle submission\n",
    "test_pred = pd.concat([test['id'], pd.DataFrame(y_test_pred, columns=['class'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Verify that we have a mix of predictions for variation classes\n",
    "test_pred['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred.to_csv(\"../assets/test_pred.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
