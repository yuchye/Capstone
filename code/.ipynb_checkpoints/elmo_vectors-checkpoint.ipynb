{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fLWcFMSF6YCP"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g2_38u_s7AX_"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../assets/train_prep.csv\", keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R_VJXlfg7Dml"
   },
   "outputs": [],
   "source": [
    "train = train[['id', 'class', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "aERk97HT7LGI",
    "outputId": "5d8ddab6-2695-4601-9824-c060a9db5153"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>cyclin dependent kinase cdks regulate variety fundamental cellular process cdk stand one last orphan cdks activate cyclin identify kinase activity reveal previous work cdk silence increase ets v e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>abstract background non small lung nsclc heterogeneous group disorder number genetic proteomic alteration c cbl e ubiquitin ligase adaptor molecule important normal homeostasis determine genetic v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>abstract background non small lung nsclc heterogeneous group disorder number genetic proteomic alteration c cbl e ubiquitin ligase adaptor molecule important normal homeostasis determine genetic v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>recent evidence demonstrate acquire uniparental disomy aupd novel mechanism pathogenetic may reduce homozygosity help identify novel myeloproliferative neoplasm mpns perform genome wide single nuc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>oncogenic monomeric casitas b lineage lymphoma cbl gene found many significance remains largely unknown several human c cbl cbl structure recently solve depict protein different stage activation c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  class  \\\n",
       "0   0      1   \n",
       "1   1      2   \n",
       "2   2      2   \n",
       "3   3      3   \n",
       "4   4      4   \n",
       "\n",
       "                                                                                                                                                                                                      text  \n",
       "0  cyclin dependent kinase cdks regulate variety fundamental cellular process cdk stand one last orphan cdks activate cyclin identify kinase activity reveal previous work cdk silence increase ets v e...  \n",
       "1  abstract background non small lung nsclc heterogeneous group disorder number genetic proteomic alteration c cbl e ubiquitin ligase adaptor molecule important normal homeostasis determine genetic v...  \n",
       "2  abstract background non small lung nsclc heterogeneous group disorder number genetic proteomic alteration c cbl e ubiquitin ligase adaptor molecule important normal homeostasis determine genetic v...  \n",
       "3  recent evidence demonstrate acquire uniparental disomy aupd novel mechanism pathogenetic may reduce homozygosity help identify novel myeloproliferative neoplasm mpns perform genome wide single nuc...  \n",
       "4  oncogenic monomeric casitas b lineage lymphoma cbl gene found many significance remains largely unknown several human c cbl cbl structure recently solve depict protein different stage activation c...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3gMWFYZr9RLu"
   },
   "outputs": [],
   "source": [
    "X = train[['id', 'text']]\n",
    "y = train['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X1RO5-YF9Ssh"
   },
   "outputs": [],
   "source": [
    "X_all_text = []\n",
    "for text in X['text']:\n",
    "    X_all_text.append(text.split())\n",
    "X_all_text = np.array(X_all_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the ELMo module (version 3) from TensorFlow Hub. The ELMo module computes contextualized word representations using character-based word representations and bidirectional LSTMs. \n",
    "\n",
    "The module supports inputs both in the form of raw text strings or tokenized text strings. It outputs fixed embeddings at each LSTM layer, a learnable aggregation of the 3 layers, and a fixed mean-pooled vector representation of the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QxFlRKQ87X8Z"
   },
   "outputs": [],
   "source": [
    "elmo = hub.Module(\"https://tfhub.dev/google/elmo/3\", trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function that will extract the ELMo vectors of all the words in a single sample and take their mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YoRGAvLK74MK"
   },
   "outputs": [],
   "source": [
    "def elmo_vectors(x):\n",
    "    embeddings = elmo(x, signature=\"default\", as_dict=True)[\"elmo\"]\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(tf.tables_initializer())\n",
    "        # return average of ELMo features\n",
    "        return sess.run(tf.reduce_mean(embeddings,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now call the function for each sample text in the X_all_text list we have created earlier. Due to memory constraints, we cannot store the entire set of ELMo vectors in memory. Instead, we write them to disk using the Pickle serialisation library using the most efficient Pickle serialisation protocol available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "sAgk_6JqKXfd",
    "outputId": "1e1fafc4-cd3d-4184-c0d9-60928010d81f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started creating pickle file at: 2020-04-08 20:04:17\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 0 of 3321 appended, duration (h:m:s): 0:00:12.152543, total elapsed time (h:m:s): 0:00:12.153543\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "now = datetime.datetime.now()\n",
    "print (\"Started creating pickle file at: {}\".format(now.strftime(\"%Y-%m-%d %H:%M:%S\")))\n",
    "num_rows = len(X_all_text)\n",
    "first_start = time.time() # track the start of the whole pickling operation\n",
    "\n",
    "for pickle_batch in range((num_rows//200)+1):\n",
    "    with open(\"../assets/elmo_vectors_\"+str(pickle_batch)+\".pickle\", \"wb\") as pickle_out:\n",
    "        max_batch_row = min(num_rows, pickle_batch*200+200)\n",
    "        for row in range(pickle_batch*200, max_batch_row):\n",
    "            row_start = time.time()\n",
    "            pickle.dump(elmo_vectors(X_all_text[row]), pickle_out, pickle.HIGHEST_PROTOCOL)\n",
    "            # Flush the contents of memory to disk as each row is processed, so that we can\n",
    "            # better track the progress of the pickling operation\n",
    "            pickle_out.flush() \n",
    "            os.fsync(pickle_out)\n",
    "            print (\"Row {} of {} appended, duration (h:m:s): {}, total elapsed time (h:m:s): {}\".format(row, num_rows,\n",
    "                   str(datetime.timedelta(seconds=time.time()-row_start)),\n",
    "                   str(datetime.timedelta(seconds=time.time()-first_start))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tqWWXp9EOUhp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "elmo_test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
